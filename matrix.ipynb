{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "acc3a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "5d568a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_bar(bar1,bar2):\n",
    "    #In the 12-position format of each bar, if the same positions in two bars all have a beat than their distance\n",
    "    #is zero, otherwise the distance will add 1\n",
    "    ##Return the distance between bar1 and bar2\n",
    "    dis_bar=0;\n",
    "    for i in range(12):\n",
    "        if(bar1[i]==bar2[i]):\n",
    "            continue\n",
    "        else:\n",
    "            dis_bar=dis_bar+1\n",
    "    return dis_bar\n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "a99b9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_measure(mea1):\n",
    "    # The correlation between each bar in one piece, the input should be in the 12-position form\n",
    "    mea1=pd.DataFrame(mea1)\n",
    "    corr_matrix=mea1.T.corr()\n",
    "    plt.figure(figsize=(10,8))\n",
    "    mask = np.zeros_like(corr_matrix, dtype=np.bool_)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "    mask[np.diag_indices_from(mask)]=False\n",
    "    plt.title(\"\")\n",
    "    sns.heatmap(corr_matrix, annot = True,mask = mask, linewidths=.5, cmap=\"YlGnBu\") \n",
    "    plt.show()\n",
    "    #plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "835c7698",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averagebeat_per_piece(piece):\n",
    "    # calculate average beats in one piece in each bar\n",
    "    num_bar=len(piece)\n",
    "    num_beat=0\n",
    "    for i in range(len(piece)):\n",
    "        l=piece[i].split(\",\")        \n",
    "        num_beat=num_beat+len(l)     \n",
    "    return num_beat/num_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "48e75ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted(piece):\n",
    "    weights=0\n",
    "    for i in range(len(piece)):            \n",
    "        if('1' in piece[i]):\n",
    "            weights=weights+2        \n",
    "        if('5' in piece[i]):\n",
    "            weights=weights+1            \n",
    "        if('9' in piece[i]):\n",
    "            weights=weights+1  \n",
    "    return weights/len(piece)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "e162bfd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_correlation(piece):\n",
    "    for i in range(len(piece)): \n",
    "        piece[i]=piece[i].split(\",\")        \n",
    "    piece=pd.DataFrame(piece)    \n",
    "    piece=piece.apply(lambda x:x.astype(float))    \n",
    "    corr_matrix=piece.T.corr()\n",
    "    min_corr=(corr_matrix.min()).min()\n",
    "    return min_corr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "2c6dfdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(piece):\n",
    "    # give a score to each song according to number of notes in each bar, minimum correlation between the bars in\n",
    "    # one piece, the expected position of note. \n",
    "    weights=weighted(piece)    \n",
    "    average_beat=averagebeat_per_piece(piece)   \n",
    "    min_corr=min_correlation(piece)\n",
    "    \n",
    "    return average_beat,min_corr,weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ed0a7",
   "metadata": {},
   "source": [
    "# Calculate three scores to each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "0ccf09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv(\"./train.csv\")\n",
    "dataset_notes=df_train[\"notes\"].tolist()\n",
    "\n",
    "for i in range(len(dataset_notes)):\n",
    "    d=dataset_notes[i]\n",
    "    d=d.replace(\"[\",'')\n",
    "    d=d.replace(\" \",'')\n",
    "    d=d.replace(\"]]\",\"\")\n",
    "    d=d.replace(\" \",\"\")\n",
    "    d=d.split(\"],\")\n",
    "    dataset_notes[i]=d   \n",
    "    \n",
    "aver_beat=[]\n",
    "min_corr=[]\n",
    "weights=[]\n",
    "for i in range(len(dataset_notes)):    \n",
    "    beat,corr,weight=scoring(dataset_notes[i])\n",
    "    aver_beat.append(beat)\n",
    "    min_corr.append(corr)\n",
    "    weights.append(weight)\n",
    "\n",
    "aver_beat=pd.DataFrame(aver_beat)\n",
    "aver_beat.columns=[\"average_beat\"]\n",
    "min_corr=pd.DataFrame(min_corr)\n",
    "min_corr.columns=[\"min_correlation\"]\n",
    "weights=pd.DataFrame(weights)\n",
    "weights.columns=[\"weights\"]\n",
    "df_train=pd.concat([df_train,aver_beat,min_corr,weights],axis=1)\n",
    "df_train.to_csv(\"train_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "cc0a47ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"./test.csv\")\n",
    "dataset_notes=df_test[\"notes\"].tolist()\n",
    "\n",
    "for i in range(len(dataset_notes)):\n",
    "    d=dataset_notes[i]\n",
    "    d=d.replace(\"[\",'')\n",
    "    d=d.replace(\" \",'')\n",
    "    d=d.replace(\"]]\",\"\")\n",
    "    d=d.replace(\" \",\"\")\n",
    "    d=d.split(\"],\")\n",
    "    dataset_notes[i]=d   \n",
    "    \n",
    "aver_beat=[]\n",
    "min_corr=[]\n",
    "weights=[]\n",
    "for i in range(len(dataset_notes)):    \n",
    "    beat,corr,weight=scoring(dataset_notes[i])\n",
    "    aver_beat.append(beat)\n",
    "    min_corr.append(corr)\n",
    "    weights.append(weight)\n",
    "\n",
    "aver_beat=pd.DataFrame(aver_beat)\n",
    "aver_beat.columns=[\"average_beat\"]\n",
    "min_corr=pd.DataFrame(min_corr)\n",
    "min_corr.columns=[\"min_correlation\"]\n",
    "weights=pd.DataFrame(weights)\n",
    "weights.columns=[\"weights\"]\n",
    "df_test=pd.concat([df_test,aver_beat,min_corr,weights],axis=1)\n",
    "df_test.to_csv(\"test_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "15825082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random=pd.read_csv(\"./random_songs.csv\")\n",
    "dataset_notes=df_random[\"notes\"].tolist()\n",
    "\n",
    "for i in range(len(dataset_notes)):\n",
    "    d=dataset_notes[i]\n",
    "    d=d.replace(\"[\",'')\n",
    "    d=d.replace(\" \",'')\n",
    "    d=d.replace(\"]]\",\"\")\n",
    "    d=d.replace(\" \",\"\")\n",
    "    d=d.split(\"],\")\n",
    "    dataset_notes[i]=d   \n",
    "    \n",
    "aver_beat=[]\n",
    "min_corr=[]\n",
    "weights=[]\n",
    "for i in range(len(dataset_notes)):    \n",
    "    beat,corr,weight=scoring(dataset_notes[i])\n",
    "    aver_beat.append(beat)\n",
    "    min_corr.append(corr)\n",
    "    weights.append(weight)\n",
    "\n",
    "aver_beat=pd.DataFrame(aver_beat)\n",
    "aver_beat.columns=[\"average_beat\"]\n",
    "min_corr=pd.DataFrame(min_corr)\n",
    "min_corr.columns=[\"min_correlation\"]\n",
    "weights=pd.DataFrame(weights)\n",
    "weights.columns=[\"weights\"]\n",
    "df_random=pd.concat([df_random,aver_beat,min_corr,weights],axis=1)\n",
    "df_random.to_csv(\"random_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "e6bba46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_markov=pd.read_csv(\"./markov_songs.csv\")\n",
    "dataset_notes=df_markov[\"notes\"].tolist()\n",
    "\n",
    "for i in range(len(dataset_notes)):\n",
    "    d=dataset_notes[i]\n",
    "    d=d.replace(\"[\",'')\n",
    "    d=d.replace(\" \",'')\n",
    "    d=d.replace(\"]]\",\"\")\n",
    "    d=d.replace(\" \",\"\")\n",
    "    d=d.split(\"],\")\n",
    "    dataset_notes[i]=d   \n",
    "    \n",
    "aver_beat=[]\n",
    "min_corr=[]\n",
    "weights=[]\n",
    "for i in range(len(dataset_notes)):    \n",
    "    beat,corr,weight=scoring(dataset_notes[i])\n",
    "    aver_beat.append(beat)\n",
    "    min_corr.append(corr)\n",
    "    weights.append(weight)\n",
    "\n",
    "aver_beat=pd.DataFrame(aver_beat)\n",
    "aver_beat.columns=[\"average_beat\"]\n",
    "min_corr=pd.DataFrame(min_corr)\n",
    "min_corr.columns=[\"min_correlation\"]\n",
    "weights=pd.DataFrame(weights)\n",
    "weights.columns=[\"weights\"]\n",
    "df_markov=pd.concat([df_markov,aver_beat,min_corr,weights],axis=1)\n",
    "df_markov.to_csv(\"markov_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651bef64",
   "metadata": {},
   "source": [
    "# Analyze between different dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a5731",
   "metadata": {},
   "source": [
    "## Average scores for different dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "ba330a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average beat per bar in training dataset is: 7.305962692746507\n",
      "Average minimum correlation in training dataset is: 0.9026131391566267\n",
      "Average weights in training dataset is: 3.9162547927432025\n"
     ]
    }
   ],
   "source": [
    "df_train=pd.read_csv(\"train_all.csv\")\n",
    "print(\"Average beat per bar in training dataset is: \"+str(df_train[\"average_beat\"].mean()))\n",
    "print(\"Average minimum correlation in training dataset is: \"+str(df_train[\"min_correlation\"].mean()))\n",
    "print(\"Average weights in training dataset is: \"+str(df_train[\"weights\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "57f7172c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average beat per bar in test dataset is: 7.386141116762393\n",
      "Average minimum correlation in test dataset is: 0.9072257866547238\n",
      "Average weights in test dataset is: 3.921956704087715\n"
     ]
    }
   ],
   "source": [
    "df_test=pd.read_csv(\"test_all.csv\")\n",
    "print(\"Average beat per bar in test dataset is: \"+str(df_test[\"average_beat\"].mean()))\n",
    "print(\"Average minimum correlation in test dataset is: \"+str(df_test[\"min_correlation\"].mean()))\n",
    "print(\"Average weights in test dataset is: \"+str(df_test[\"weights\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "066f01c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average beat per bar in random dataset is: 5.483\n",
      "Average minimum correlation in random dataset is: 0.851600172949185\n",
      "Average weights in random dataset is: 2.732\n"
     ]
    }
   ],
   "source": [
    "df_random=pd.read_csv(\"random_all.csv\")\n",
    "print(\"Average beat per bar in random dataset is: \"+str(df_random[\"average_beat\"].mean()))\n",
    "print(\"Average minimum correlation in random dataset is: \"+str(df_random[\"min_correlation\"].mean()))\n",
    "print(\"Average weights in random dataset is: \"+str(df_random[\"weights\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "7f79f39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average beat per bar in markov dataset is: 7.7285\n",
      "Average minimum correlation in markov dataset is: 0.9472839559711381\n",
      "Average weights in markov dataset is: 3.997\n"
     ]
    }
   ],
   "source": [
    "df_markov=pd.read_csv(\"markov_all.csv\")\n",
    "print(\"Average beat per bar in markov dataset is: \"+str(df_markov[\"average_beat\"].mean()))\n",
    "print(\"Average minimum correlation in markov dataset is: \"+str(df_markov[\"min_correlation\"].mean()))\n",
    "print(\"Average weights in markov dataset is: \"+str(df_markov[\"weights\"].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e3cc3",
   "metadata": {},
   "source": [
    "# Find the best and worest song in Markov(generated) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f53088",
   "metadata": {},
   "source": [
    "#### We need to uniform standards for the three scores to get a general score. For beat per bar, it should be close to that of the test set. For minimum correlation, it should be as big as possible. For weights, it should be as close to 4(big) as possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "2f8ee57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def general_score(average_beat,min_correlation,weights):\n",
    "    final_score=weights/4+min_correlation+(1-(average_beat-7.386)**2)    # 7.386 is the average beat in test set\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7921715f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
